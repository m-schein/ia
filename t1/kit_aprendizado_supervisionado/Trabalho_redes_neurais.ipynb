{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g5GN3EpDn4b"
      },
      "source": [
        "\n",
        "Imports e definição do dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpxhsZya71hk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQhkJUZODtd1"
      },
      "source": [
        "Carregamento do dataset cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQQvrT5v785X"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de dados CIFAR-10\n",
        "cifar10 = keras.datasets.cifar10\n",
        "#Carrega duas tuplas, representando os dados de treinamento e de teste.\n",
        "#Cada tupla tem as imagens e os respectivos rótulos\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwHzFJajDxZt"
      },
      "source": [
        "O código abaixo mostra as 10 primeiras imagens de treino e teste do cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJipJNqX9zsJ"
      },
      "outputs": [],
      "source": [
        "# Defina as classes do CIFAR-10\n",
        "class_names = ['Avião', 'Automóvel', 'Pássaro', 'Gato', 'Cervo',\n",
        "               'Cachorro', 'Sapo', 'Cavalo', 'Navio', 'Caminhão']\n",
        "\n",
        "# Crie um dicionário para mapear as classes para as imagens correspondentes\n",
        "class_to_image = {}\n",
        "for i in range(10):\n",
        "    index = (test_labels == i).nonzero()[0][0]  # Encontre o primeiro índice da classe\n",
        "    class_to_image[i] = test_images[index]\n",
        "\n",
        "# Mostre uma imagem de cada classe\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.xticks([])  # Remova os rótulos do eixo x\n",
        "    plt.yticks([])  # Remova os rótulos do eixo y\n",
        "    plt.imshow(class_to_image[i])\n",
        "    plt.xlabel(class_names[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxLXNIaD4lq"
      },
      "source": [
        "Abaixo, convertemos os rótulos escalares (números de 0 a 9) para one-hot encoding.\n",
        "\n",
        "Não é necessário realizar este passo, caso seja utilizada a função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h1CJgPJ9MTt"
      },
      "outputs": [],
      "source": [
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymnOpRMETAu"
      },
      "source": [
        "Função que retorna uma rede neural para o cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPrIRBmT8XiN"
      },
      "outputs": [],
      "source": [
        "# Crie o modelo de rede neural convolucional simples\n",
        "def get_cifar10_network():\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),#(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjmscwcQErIx"
      },
      "source": [
        "Trecho para treinar e avaliar a rede neural.\n",
        "O treino é realizado com os dados de treino e a avaliação do modelo é realizada nos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uN8v8_m8cvR"
      },
      "outputs": [],
      "source": [
        "# Treine o modelo\n",
        "model = get_cifar10_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKkBlEy1ExHj"
      },
      "source": [
        "Tarefa\n",
        "Escreva código para executar redes neurais nos seguintes datasets:\n",
        "\n",
        "MNIST (pode aproveitar o codigo existente)\n",
        "Fashion MNIST\n",
        "CIFAR-10\n",
        "CIFAR-100\n",
        "Cada execução deve ser por 10 épocas.\n",
        "\n",
        "Você deve preencher as funções a seguir para retornarem a rede neural com a melhor configuração que você conseguiu para cada dataset (a do MNIST deve ser feita na get_mnist_network() acima). O notebook deve ser entregue com a rede neural que obteve a melhor performance em cada conjunto de dados.\n",
        "\n",
        "IMPORTANTE: as funções não devem TREINAR nem AVALIAR as redes neurais, apenas instancia-las e retorna-las.\n",
        "\n",
        "Ao final, preencha o dict results com o desempenho encontrado em cada execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gN14IpXnFfCQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_fashion_mnist_network():\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(124, 124, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(62, 62, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "  ])\n",
        "\n",
        "  # Compile o modelo\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def get_mnist_network():\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(124, 124, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(62, 62, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "  ])\n",
        "\n",
        "  # Compile o modelo\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "def get_cifar100_network():\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(32, 32, 3)),#(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(124, 124, 3)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(62, 62, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')  # 100 classes de saída\n",
        "  ])\n",
        "\n",
        "  # Compile o modelo\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model\n",
        "\n",
        "#Para este caso, modifique a função já oferecida neste notebook\n",
        "def get_cifar10_network():\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(32, 32, 3)),#(32, 32, 3) porque as imagens são 32X32 e RGB, portanto, tendo 3 canais de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(124, 124, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(62, 62, 1)),#(28, 28, 1) porque as imagens são 28x28 e Gray-Scale, portanto, tendo 1 canal de cor\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')  # 10 classes de saída\n",
        "    ])\n",
        "\n",
        "    # Compile o modelo\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = keras.datasets.cifar10\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\n",
        "\n",
        "# Treine o modelo\n",
        "model = get_cifar10_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "Uzld3FmKBGKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e39e85-5d0f-418f-9166-1b68e7b5698e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          (None, 30, 30, 128)       3584      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 15, 15, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 13, 13, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 2, 2, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131,402\n",
            "Trainable params: 131,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 232s 148ms/step - loss: 1.8053 - accuracy: 0.3741\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 223s 143ms/step - loss: 1.4025 - accuracy: 0.4999\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 218s 139ms/step - loss: 1.2811 - accuracy: 0.5503\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 218s 139ms/step - loss: 1.1862 - accuracy: 0.5830\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 1.1160 - accuracy: 0.6117\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 218s 139ms/step - loss: 1.0574 - accuracy: 0.6321\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 1.0155 - accuracy: 0.6471\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.9733 - accuracy: 0.6620\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 219s 140ms/step - loss: 0.9400 - accuracy: 0.6732\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 0.9083 - accuracy: 0.6863\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 1.0794 - accuracy: 0.6350\n",
            "Acurácia no conjunto de teste: 63.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FkJcWL9YAVC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdbae59-1d2a-4643-fd0e-5376ab3ba9db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 128)       3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               6500      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 137,252\n",
            "Trainable params: 137,252\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 234s 146ms/step - loss: 4.2387 - accuracy: 0.0625\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 215s 137ms/step - loss: 3.6786 - accuracy: 0.1409\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 3.4153 - accuracy: 0.1836\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 3.2494 - accuracy: 0.2124\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 217s 139ms/step - loss: 3.1334 - accuracy: 0.2350\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 218s 139ms/step - loss: 3.0346 - accuracy: 0.2520\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 2.9691 - accuracy: 0.2651\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 2.9222 - accuracy: 0.2741\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 2.8691 - accuracy: 0.2848\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 214s 137ms/step - loss: 2.8238 - accuracy: 0.2931\n",
            "313/313 [==============================] - 12s 36ms/step - loss: 3.0266 - accuracy: 0.2673\n",
            "Acurácia no conjunto de teste: 26.73%\n"
          ]
        }
      ],
      "source": [
        "cifar100 = keras.datasets.cifar100\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n",
        "num_classes = 100\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\n",
        "\n",
        "# Treine o modelo\n",
        "model = get_cifar100_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\n",
        "\n",
        "# Treine o modelo\n",
        "model = get_mnist_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "2ercRsJrA7HN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc7eb40-46aa-4584-e2c6-337e475f2a30"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 13, 13, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 11, 11, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,810\n",
            "Trainable params: 116,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 196s 103ms/step - loss: 0.2479 - accuracy: 0.9328\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 189s 101ms/step - loss: 0.0885 - accuracy: 0.9737\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.0718 - accuracy: 0.9784\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 194s 104ms/step - loss: 0.0601 - accuracy: 0.9821\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0511 - accuracy: 0.9842\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0453 - accuracy: 0.9861\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0368 - accuracy: 0.9885\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.0369 - accuracy: 0.9890\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0320 - accuracy: 0.9900\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 187s 100ms/step - loss: 0.0276 - accuracy: 0.9913\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.0704 - accuracy: 0.9833\n",
            "Acurácia no conjunto de teste: 98.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Converter para codificação one-hot dos labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n",
        "#Não é necessário se utilizar como função de custo esparse_categorical_cross_entropy\n",
        "\n",
        "# Treine o modelo\n",
        "model = get_fashion_mnist_network()\n",
        "model.fit(train_images, train_labels, epochs=10)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Acurácia no conjunto de teste: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "SkAx16UGBBv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d336d2e-5150-4f1b-9168-f6886df22b8c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 13, 13, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 11, 11, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,810\n",
            "Trainable params: 116,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 193s 103ms/step - loss: 0.5837 - accuracy: 0.7992\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 189s 101ms/step - loss: 0.4006 - accuracy: 0.8526\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 189s 101ms/step - loss: 0.3607 - accuracy: 0.8673\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.3284 - accuracy: 0.8787\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.3089 - accuracy: 0.8852\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 188s 100ms/step - loss: 0.2951 - accuracy: 0.8903\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 193s 103ms/step - loss: 0.2815 - accuracy: 0.8949\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 190s 101ms/step - loss: 0.2700 - accuracy: 0.8992\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 190s 102ms/step - loss: 0.2600 - accuracy: 0.9025\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 189s 101ms/step - loss: 0.2472 - accuracy: 0.9076\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 0.3535 - accuracy: 0.8806\n",
            "Acurácia no conjunto de teste: 88.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iERVafMPF2Tn"
      },
      "source": [
        "Preencha o dict abaixo substituindo os None com a acuracia final (acc) e o tempo de treinamento (time) encontrado no seu experimento pra cada dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEUK1xk6Fk48"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"mnist\": {\"time\": None, \"acc\": None},\n",
        "    \"fashion_mnist\": {\"time\": None, \"acc\": None},\n",
        "    \"cifar10\": {\"time\": None, \"acc\": None},\n",
        "    \"cifar100\": {\"time\": None, \"acc\": None},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}